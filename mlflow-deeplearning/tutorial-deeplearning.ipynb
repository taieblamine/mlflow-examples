{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a326440",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mlflow torch torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec20b60",
   "metadata": {},
   "source": [
    "# Step 1: Create a new experiment\n",
    "Create a new MLflow experiment for the tutorial and enable system metrics monitoring. Here we set the monitoring interval to 1 second because the training will be quick, but for longer training runs, you can set it to a larger value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fdd9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "# The set_experiment API creates a new experiment if it doesn't exist.\n",
    "mlflow.set_experiment(\"Deep Learning Experiment\")\n",
    "\n",
    "# IMPORTANT: Enable system metrics monitoring\n",
    "mlflow.config.enable_system_metrics_logging()\n",
    "mlflow.config.set_system_metrics_sampling_interval(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b311d4d",
   "metadata": {},
   "source": [
    "# Step 2: Prepare the dataset\n",
    "In this example, we will use the FashionMNIST dataset, which is a collection of 28x28 grayscale images of 10 different types of clothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ee1912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load and prepare data\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    ")\n",
    "train_dataset = datasets.FashionMNIST(\n",
    "    \"data\", train=True, download=True, transform=transform\n",
    ")\n",
    "test_dataset = datasets.FashionMNIST(\"data\", train=False, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab62413",
   "metadata": {},
   "source": [
    "# Step 3: Define the model and optimizer\n",
    "Define a simple MLP model with 2 hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e01dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "model = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd50aa7",
   "metadata": {},
   "source": [
    "Then, define the training parameters and optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b181f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "params = {\n",
    "    \"epochs\": 5,\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": 64,\n",
    "    \"optimizer\": \"SGD\",\n",
    "    \"model_type\": \"MLP\",\n",
    "    \"hidden_units\": [512, 512],\n",
    "}\n",
    "\n",
    "# Define optimizer and loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=params[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19affb6f",
   "metadata": {},
   "source": [
    "# Step 4: Train the model\n",
    "Now we are ready to train the model. Inside the training loop, we log the metrics and checkpoints to MLflow. The key points in this code are:\n",
    "\n",
    "- Initiate an MLflow run context to start a new run that we will log the model and metadata to.\n",
    "- Log training parameters using mlflow.log_params.\n",
    "- Log various metrics using mlflow.log_metrics.\n",
    "- Save checkpoints for each epoch using mlflow.pytorch.log_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e291789",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    # Log training parameters\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    for epoch in range(params[\"epochs\"]):\n",
    "        model.train()\n",
    "        train_loss, correct, total = 0, 0, 0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate metrics\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "            # Log batch metrics (every 100 batches)\n",
    "            if batch_idx % 100 == 0:\n",
    "                batch_loss = train_loss / (batch_idx + 1)\n",
    "                batch_acc = 100.0 * correct / total\n",
    "                mlflow.log_metrics(\n",
    "                    {\"batch_loss\": batch_loss, \"batch_accuracy\": batch_acc},\n",
    "                    step=epoch * len(train_loader) + batch_idx,\n",
    "                )\n",
    "\n",
    "        # Calculate epoch metrics\n",
    "        epoch_loss = train_loss / len(train_loader)\n",
    "        epoch_acc = 100.0 * correct / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                loss = loss_fn(output, target)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = output.max(1)\n",
    "                val_total += target.size(0)\n",
    "                val_correct += predicted.eq(target).sum().item()\n",
    "\n",
    "        # Calculate and log epoch validation metrics\n",
    "        val_loss = val_loss / len(test_loader)\n",
    "        val_acc = 100.0 * val_correct / val_total\n",
    "\n",
    "        # Log epoch metrics\n",
    "        mlflow.log_metrics(\n",
    "            {\n",
    "                \"train_loss\": epoch_loss,\n",
    "                \"train_accuracy\": epoch_acc,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_accuracy\": val_acc,\n",
    "            },\n",
    "            step=epoch,\n",
    "        )\n",
    "        # Log checkpoint at the end of each epoch\n",
    "        mlflow.pytorch.log_model(model, name=f\"checkpoint_{epoch}\")\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1}/{params['epochs']}, \"\n",
    "            f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}%, \"\n",
    "            f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\"\n",
    "        )\n",
    "\n",
    "    # Log the final trained model\n",
    "    model_info = mlflow.pytorch.log_model(model, name=\"final_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bab863b",
   "metadata": {},
   "source": [
    "# Step 5: View the training results in the MLflow UI\n",
    "To see the results of training, you can access the MLflow UI by navigating to the URL of the Tracking Server. If you have not started one, open a new terminal and run the following command at the root of the MLflow project and access the UI at http://localhost:5000 (or the port number you specified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036fb22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mlflow ui --port 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c482463",
   "metadata": {},
   "source": [
    "# Step 6: Load back the model and run inference\n",
    "You can load the final model or checkpoint from MLflow using the mlflow.pytorch.load_model function. Let's run the loaded model on the test set and evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49171d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the final model\n",
    "loaded_model = mlflow.pytorch.load_model(\"runs:/<run_id>/final_model\")\n",
    "# or load a checkpoint\n",
    "# model = mlflow.pytorch.load_model(\"runs:/<run_id>/checkpoint_<epoch>\")\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "# Resume the previous run to log test metrics\n",
    "with mlflow.start_run(run_id=run.info.run_id) as run:\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_correct, test_total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        test_total += target.size(0)\n",
    "        test_correct += predicted.eq(target).sum().item()\n",
    "\n",
    "    # Calculate and log final test metrics\n",
    "    test_loss = test_loss / len(test_loader)\n",
    "    test_acc = 100.0 * test_correct / test_total\n",
    "\n",
    "    mlflow.log_metrics({\"test_loss\": test_loss, \"test_accuracy\": test_acc})\n",
    "    print(f\"Final Test Accuracy: {test_acc:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
